{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8342,"status":"ok","timestamp":1673969491643,"user":{"displayName":"Daan Koomen","userId":"05289433156715552258"},"user_tz":-60},"id":"T5fhVUh4rUfy","outputId":"76ac75b4-2d3e-45cb-f600-44be1c022563"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import sys\n","import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","py_file_location = 'path drive here'\n","sys.path.append(os.path.abspath(py_file_location))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC8xpDamrFaE"},"outputs":[],"source":["import torch\n","import torch.utils.data\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.autograd import Variable\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from PIL import Image\n","\n","import re\n","\n","import os\n","import copy\n","from helpers import makedir, find_high_activation_crop\n","import model\n","import push\n","import train_and_test as tnt\n","import save\n","from log import create_logger\n","from preprocess import mean, std, preprocess_input_function, undo_preprocess_input_function\n","\n","import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('-gpuid', nargs=1, type=str, default='0')\n","parser.add_argument('-modeldir', nargs=1, type=str)\n","parser.add_argument('-model', nargs=1, type=str)\n","parser.add_argument('-imgdir', nargs=1, type=str)\n","parser.add_argument('-img', nargs=1, type=str)\n","parser.add_argument('-imgclass', nargs=1, type=int, default=-1)\n","args, unknown = parser.parse_known_args()\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = args.gpuid[0]\n","predicted=[]\n","#for img in 45, 46:\n","  #for img in range(61,73):\n","for img in 45, 46, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72:\n","\n","    # specify the test image to be analyzed\n","    test_image_dir = args.imgdir = 'path test set here' #'./local_analysis/Painted_Bunting_Class15_0081/'\n","    test_image_name = args.img = str(img) + '.jpg' #'Painted_Bunting_0081_15230.jpg'\n","    test_image_label = args.imgclass = \"correct class here\" #15 \n","\n","    test_image_path = os.path.join(test_image_dir, test_image_name)\n","    Image.open(test_image_path)\n","\n","    # load the model\n","    check_test_accu = False\n","\n","    load_model_dir = args.modeldir = 'path model here' #'./saved_models/vgg19/001/'\n","  \n","\n","\n","\n","\n","    model_base_architecture = load_model_dir.split('/')[8]\n","    experiment_run = '/'.join(load_model_dir.split('/')[9:])\n","\n","    save_analysis_path = os.path.join(test_image_dir, model_base_architecture,\n","                                      experiment_run, load_model_name, test_image_name)\n","    print(save_analysis_path)\n","\n","    makedir(save_analysis_path)\n","\n","    log, logclose = create_logger(log_filename=os.path.join(save_analysis_path, 'local_analysis.log'))\n","\n","    load_model_path = os.path.join(load_model_dir, load_model_name)\n","    epoch_number_str = re.search(r'\\d+', load_model_name).group(0)\n","    start_epoch_number = int(epoch_number_str)\n","\n","    log('load model from ' + load_model_path)\n","    log('model base architecture: ' + model_base_architecture)\n","    log('experiment run: ' + experiment_run)\n","\n","    ppnet = torch.load(load_model_path)\n","    ppnet = ppnet.cuda()\n","    ppnet_multi = torch.nn.DataParallel(ppnet)\n","\n","    img_size = ppnet_multi.module.img_size\n","    prototype_shape = ppnet.prototype_shape\n","    max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\n","\n","    class_specific = True\n","\n","    normalize = transforms.Normalize(mean=mean,\n","                                    std=std)\n","\n","    # load the test data and check test accuracy\n","    from settings import test_dir\n","    if check_test_accu:\n","        test_batch_size = 100\n","\n","        test_dataset = datasets.ImageFolder(\n","            test_dir,\n","            transforms.Compose([\n","                transforms.Resize(size=(img_size, img_size)),\n","                transforms.ToTensor(),\n","                normalize,\n","            ]))\n","        test_loader = torch.utils.data.DataLoader(\n","            test_dataset, batch_size=test_batch_size, shuffle=True,\n","            num_workers=4, pin_memory=False)\n","        log('test set size: {0}'.format(len(test_loader.dataset)))\n","\n","        accu = tnt.test(model=ppnet_multi, dataloader=test_loader,\n","                        class_specific=class_specific, log=print)\n","\n","    ##### SANITY CHECK\n","    # confirm prototype class identity\n","    load_img_dir = os.path.join(load_model_dir, 'img')\n","\n","    prototype_info = np.load(os.path.join(load_img_dir, 'epoch-'+epoch_number_str, 'bb'+epoch_number_str+'.npy'))\n","    prototype_img_identity = prototype_info[:, -1]\n","\n","    log('Prototypes are chosen from ' + str(len(set(prototype_img_identity))) + ' number of classes.')\n","    log('Their class identities are: ' + str(prototype_img_identity))\n","\n","    # confirm prototype connects most strongly to its own class\n","    prototype_max_connection = torch.argmax(ppnet.last_layer.weight, dim=0)\n","    prototype_max_connection = prototype_max_connection.cpu().numpy()\n","    if np.sum(prototype_max_connection == prototype_img_identity) == ppnet.num_prototypes:\n","        log('All prototypes connect most strongly to their respective classes.')\n","    else:\n","        log('WARNING: Not all prototypes connect most strongly to their respective classes.')\n","\n","    ##### HELPER FUNCTIONS FOR PLOTTING\n","    def save_preprocessed_img(fname, preprocessed_imgs, index=0):\n","        img_copy = copy.deepcopy(preprocessed_imgs[index:index+1])\n","        undo_preprocessed_img = undo_preprocess_input_function(img_copy)\n","        print('image index {0} in batch'.format(index))\n","        undo_preprocessed_img = undo_preprocessed_img[0]\n","        undo_preprocessed_img = undo_preprocessed_img.detach().cpu().numpy()\n","        undo_preprocessed_img = np.transpose(undo_preprocessed_img, [1,2,0])\n","        \n","        plt.imsave(fname, undo_preprocessed_img)\n","        return undo_preprocessed_img\n","\n","    def save_prototype(fname, epoch, index):\n","        p_img = plt.imread(os.path.join(load_img_dir, 'epoch-'+str(epoch), 'prototype-img'+str(index)+'.png'))\n","        #plt.axis('off')\n","        plt.imsave(fname, p_img)\n","        \n","    def save_prototype_self_activation(fname, epoch, index):\n","        p_img = plt.imread(os.path.join(load_img_dir, 'epoch-'+str(epoch),\n","                                        'prototype-img-original_with_self_act'+str(index)+'.png'))\n","        #plt.axis('off')\n","        plt.imsave(fname, p_img)\n","\n","    def save_prototype_original_img_with_bbox(fname, epoch, index,\n","                                              bbox_height_start, bbox_height_end,\n","                                              bbox_width_start, bbox_width_end, color=(0, 255, 255)):\n","        p_img_bgr = cv2.imread(os.path.join(load_img_dir, 'epoch-'+str(epoch), 'prototype-img-original'+str(index)+'.png'))\n","        cv2.rectangle(p_img_bgr, (bbox_width_start, bbox_height_start), (bbox_width_end-1, bbox_height_end-1),\n","                      color, thickness=2)\n","        p_img_rgb = p_img_bgr[...,::-1]\n","        p_img_rgb = np.float32(p_img_rgb) / 255\n","        plt.imshow(p_img_rgb)\n","        #plt.axis('off')\n","        plt.imsave(fname, p_img_rgb)\n","\n","    def imsave_with_bbox(fname, img_rgb, bbox_height_start, bbox_height_end,\n","                        bbox_width_start, bbox_width_end, color=(0, 255, 255)):\n","        img_bgr_uint8 = cv2.cvtColor(np.uint8(255*img_rgb), cv2.COLOR_RGB2BGR)\n","        cv2.rectangle(img_bgr_uint8, (bbox_width_start, bbox_height_start), (bbox_width_end-1, bbox_height_end-1),\n","                      color, thickness=2)\n","        img_rgb_uint8 = img_bgr_uint8[...,::-1]\n","        img_rgb_float = np.float32(img_rgb_uint8) / 255\n","        plt.imshow(img_rgb_float)\n","        #plt.axis('off')\n","        plt.imsave(fname, img_rgb_float)\n","\n","    # load the test image and forward it through the network\n","    preprocess = transforms.Compose([\n","      transforms.Resize((img_size,img_size)),\n","      transforms.ToTensor(),\n","      normalize\n","    ])\n","\n","    img_pil = Image.open(test_image_path)\n","    img_tensor = preprocess(img_pil)\n","    img_variable = Variable(img_tensor.unsqueeze(0))\n","\n","    images_test = img_variable.cuda()\n","    labels_test = torch.tensor([test_image_label])\n","\n","    logits, min_distances = ppnet_multi(images_test)\n","    conv_output, distances = ppnet.push_forward(images_test)\n","    prototype_activations = ppnet.distance_2_similarity(min_distances)\n","    prototype_activation_patterns = ppnet.distance_2_similarity(distances)\n","    if ppnet.prototype_activation_function == 'linear':\n","        prototype_activations = prototype_activations + max_dist\n","        prototype_activation_patterns = prototype_activation_patterns + max_dist\n","\n","    tables = []\n","    for i in range(logits.size(0)):\n","        tables.append((torch.argmax(logits, dim=1)[i].item(), labels_test[i].item()))\n","        log(str(i) + ' ' + str(tables[-1]))\n","\n","    idx = 0\n","    predicted_cls = tables[idx][0]\n","    predicted.append(predicted_cls)\n","    correct_cls = tables[idx][1]\n","    log('Predicted: ' + str(predicted_cls))\n","    log('Actual: ' + str(correct_cls))\n","    original_img = save_preprocessed_img(os.path.join(save_analysis_path, 'original_img.png'),\n","                                        images_test, idx)\n","\n","    ##### MOST ACTIVATED (NEAREST) 10 PROTOTYPES OF THIS IMAGE\n","    makedir(os.path.join(save_analysis_path, 'most_activated_prototypes'))\n","\n","    log('Most activated 10 prototypes of this image:')\n","    array_act, sorted_indices_act = torch.sort(prototype_activations[idx])\n","    for i in range(1,11):\n","        log('top {0} activated prototype for this image:'.format(i))\n","        save_prototype(os.path.join(save_analysis_path, 'most_activated_prototypes',\n","                                    'top-%d_activated_prototype.png' % i),\n","                      start_epoch_number, sorted_indices_act[-i].item())\n","        save_prototype_original_img_with_bbox(fname=os.path.join(save_analysis_path, 'most_activated_prototypes',\n","                                                                'top-%d_activated_prototype_in_original_pimg.png' % i),\n","                                              epoch=start_epoch_number,\n","                                              index=sorted_indices_act[-i].item(),\n","                                              bbox_height_start=prototype_info[sorted_indices_act[-i].item()][1],\n","                                              bbox_height_end=prototype_info[sorted_indices_act[-i].item()][2],\n","                                              bbox_width_start=prototype_info[sorted_indices_act[-i].item()][3],\n","                                              bbox_width_end=prototype_info[sorted_indices_act[-i].item()][4],\n","                                              color=(0, 255, 255))\n","        save_prototype_self_activation(os.path.join(save_analysis_path, 'most_activated_prototypes',\n","                                                    'top-%d_activated_prototype_self_act.png' % i),\n","                                      start_epoch_number, sorted_indices_act[-i].item())\n","        log('prototype index: {0}'.format(sorted_indices_act[-i].item()))\n","        log('prototype class identity: {0}'.format(prototype_img_identity[sorted_indices_act[-i].item()]))\n","        if prototype_max_connection[sorted_indices_act[-i].item()] != prototype_img_identity[sorted_indices_act[-i].item()]:\n","            log('prototype connection identity: {0}'.format(prototype_max_connection[sorted_indices_act[-i].item()]))\n","        log('activation value (similarity score): {0}'.format(array_act[-i]))\n","        log('last layer connection with predicted class: {0}'.format(ppnet.last_layer.weight[predicted_cls][sorted_indices_act[-i].item()]))\n","        \n","        activation_pattern = prototype_activation_patterns[idx][sorted_indices_act[-i].item()].detach().cpu().numpy()\n","        upsampled_activation_pattern = cv2.resize(activation_pattern, dsize=(img_size, img_size),\n","                                                  interpolation=cv2.INTER_CUBIC)\n","        \n","        # show the most highly activated patch of the image by this prototype\n","        high_act_patch_indices = find_high_activation_crop(upsampled_activation_pattern)\n","        high_act_patch = original_img[high_act_patch_indices[0]:high_act_patch_indices[1],\n","                                      high_act_patch_indices[2]:high_act_patch_indices[3], :]\n","        log('most highly activated patch of the chosen image by this prototype:')\n","        #plt.axis('off')\n","        plt.imsave(os.path.join(save_analysis_path, 'most_activated_prototypes',\n","                                'most_highly_activated_patch_by_top-%d_prototype.png' % i),\n","                  high_act_patch)\n","        log('most highly activated patch by this prototype shown in the original image:')\n","        imsave_with_bbox(fname=os.path.join(save_analysis_path, 'most_activated_prototypes',\n","                                'most_highly_activated_patch_in_original_img_by_top-%d_prototype.png' % i),\n","                        img_rgb=original_img,\n","                        bbox_height_start=high_act_patch_indices[0],\n","                        bbox_height_end=high_act_patch_indices[1],\n","                        bbox_width_start=high_act_patch_indices[2],\n","                        bbox_width_end=high_act_patch_indices[3], color=(0, 255, 255))\n","        \n","        # show the image overlayed with prototype activation map\n","        rescaled_activation_pattern = upsampled_activation_pattern - np.amin(upsampled_activation_pattern)\n","        rescaled_activation_pattern = rescaled_activation_pattern / np.amax(rescaled_activation_pattern)\n","        heatmap = cv2.applyColorMap(np.uint8(255*rescaled_activation_pattern), cv2.COLORMAP_JET)\n","        heatmap = np.float32(heatmap) / 255\n","        heatmap = heatmap[...,::-1]\n","        overlayed_img = 0.5 * original_img + 0.3 * heatmap\n","        log('prototype activation map of the chosen image:')\n","        #plt.axis('off')\n","        plt.imsave(os.path.join(save_analysis_path, 'most_activated_prototypes',\n","                                'prototype_activation_map_by_top-%d_prototype.png' % i),\n","                  overlayed_img)\n","        log('--------------------------------------------------------------')\n","\n","    #### PROTOTYPES FROM TOP-k CLASSES\n","    k = 2\n","    log('Prototypes from top-%d classes:' % k)\n","    topk_logits, topk_classes = torch.topk(logits[idx], k=k)\n","    for i,c in enumerate(topk_classes.detach().cpu().numpy()):\n","        makedir(os.path.join(save_analysis_path, 'top-%d_class_prototypes' % (i+1)))\n","\n","        log('top %d predicted class: %d' % (i+1, c))\n","        log('logit of the class: %f' % topk_logits[i])\n","        class_prototype_indices = np.nonzero(ppnet.prototype_class_identity.detach().cpu().numpy()[:, c])[0]\n","        class_prototype_activations = prototype_activations[idx][class_prototype_indices]\n","        _, sorted_indices_cls_act = torch.sort(class_prototype_activations)\n","\n","        prototype_cnt = 1\n","        for j in reversed(sorted_indices_cls_act.detach().cpu().numpy()):\n","            prototype_index = class_prototype_indices[j]\n","            save_prototype(os.path.join(save_analysis_path, 'top-%d_class_prototypes' % (i+1),\n","                                        'top-%d_activated_prototype.png' % prototype_cnt),\n","                          start_epoch_number, prototype_index)\n","            save_prototype_original_img_with_bbox(fname=os.path.join(save_analysis_path, 'top-%d_class_prototypes' % (i+1),\n","                                                                    'top-%d_activated_prototype_in_original_pimg.png' % prototype_cnt),\n","                                                  epoch=start_epoch_number,\n","                                                  index=prototype_index,\n","                                                  bbox_height_start=prototype_info[prototype_index][1],\n","                                                  bbox_height_end=prototype_info[prototype_index][2],\n","                                                  bbox_width_start=prototype_info[prototype_index][3],\n","                                                  bbox_width_end=prototype_info[prototype_index][4],\n","                                                  color=(0, 255, 255))\n","            save_prototype_self_activation(os.path.join(save_analysis_path, 'top-%d_class_prototypes' % (i+1),\n","                                                        'top-%d_activated_prototype_self_act.png' % prototype_cnt),\n","                                          start_epoch_number, prototype_index)\n","            log('prototype index: {0}'.format(prototype_index))\n","            log('prototype class identity: {0}'.format(prototype_img_identity[prototype_index]))\n","            if prototype_max_connection[prototype_index] != prototype_img_identity[prototype_index]:\n","                log('prototype connection identity: {0}'.format(prototype_max_connection[prototype_index]))\n","            log('activation value (similarity score): {0}'.format(prototype_activations[idx][prototype_index]))\n","            log('last layer connection: {0}'.format(ppnet.last_layer.weight[c][prototype_index]))\n","            \n","            activation_pattern = prototype_activation_patterns[idx][prototype_index].detach().cpu().numpy()\n","            upsampled_activation_pattern = cv2.resize(activation_pattern, dsize=(img_size, img_size),\n","                                                      interpolation=cv2.INTER_CUBIC)\n","            \n","            # show the most highly activated patch of the image by this prototype\n","            high_act_patch_indices = find_high_activation_crop(upsampled_activation_pattern)\n","            high_act_patch = original_img[high_act_patch_indices[0]:high_act_patch_indices[1],\n","                                          high_act_patch_indices[2]:high_act_patch_indices[3], :]\n","            log('most highly activated patch of the chosen image by this prototype:')\n","            #plt.axis('off')\n","            plt.imsave(os.path.join(save_analysis_path, 'top-%d_class_prototypes' % (i+1),\n","                                    'most_highly_activated_patch_by_top-%d_prototype.png' % prototype_cnt),\n","                      high_act_patch)\n","            log('most highly activated patch by this prototype shown in the original image:')\n","            imsave_with_bbox(fname=os.path.join(save_analysis_path, 'top-%d_class_prototypes' % (i+1),\n","                                                'most_highly_activated_patch_in_original_img_by_top-%d_prototype.png' % prototype_cnt),\n","                            img_rgb=original_img,\n","                            bbox_height_start=high_act_patch_indices[0],\n","                            bbox_height_end=high_act_patch_indices[1],\n","                            bbox_width_start=high_act_patch_indices[2],\n","                            bbox_width_end=high_act_patch_indices[3], color=(0, 255, 255))\n","            \n","            # show the image overlayed with prototype activation map\n","            rescaled_activation_pattern = upsampled_activation_pattern - np.amin(upsampled_activation_pattern)\n","            rescaled_activation_pattern = rescaled_activation_pattern / np.amax(rescaled_activation_pattern)\n","            heatmap = cv2.applyColorMap(np.uint8(255*rescaled_activation_pattern), cv2.COLORMAP_JET)\n","            heatmap = np.float32(heatmap) / 255\n","            heatmap = heatmap[...,::-1]\n","            overlayed_img = 0.5 * original_img + 0.3 * heatmap\n","            log('prototype activation map of the chosen image:')\n","            plt.axis('on')\n","            plt.imsave(os.path.join(save_analysis_path, 'top-%d_class_prototypes' % (i+1),\n","                                    'prototype_activation_map_by_top-%d_prototype.png' % prototype_cnt),\n","                      overlayed_img)\n","            log('--------------------------------------------------------------')\n","            prototype_cnt += 1\n","        log('***************************************************************')\n","\n","    if predicted_cls == correct_cls:\n","        log('Prediction is correct.')\n","    else:\n","        log('Prediction is wrong.')\n","\n","    logclose()\n","\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"_LY6ukvyG7_j"}},{"cell_type":"code","source":["print(predicted)"],"metadata":{"id":"uKiStP2bJDbO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673971896909,"user_tz":-60,"elapsed":19,"user":{"displayName":"Daan Koomen","userId":"05289433156715552258"}},"outputId":"0378bd36-9963-4528-f991-211671f1c44f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8Wl79IRDhDW"},"outputs":[],"source":["actual____XX = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n","\n","\n","\n","predicted_1A = 'prediction here'\n","predicted_1B =\n","predicted_1C =\n","predicted_1D =\n","predicted_1E =\n","\n","predicted_2A =\n","predicted_2B =\n","predicted_2C =\n","predicted_2D =\n","predicted_2E =\n","\n","predicted_3A =\n","predicted_3B =\n","predicted_3C =\n","predicted_3D =\n","predicted_3E =\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"oqaVr2K0IdiI"}},{"cell_type":"code","source":[],"metadata":{"id":"9BtK5uxWHJ1n"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1GYSBxozsqnlTzdBtId_nR4ovUyTi6e0b","authorship_tag":"ABX9TyOEHaOQI0BgrAmcji+tOhlj"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}