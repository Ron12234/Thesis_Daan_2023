{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"C8EY623_WP-B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675090363316,"user_tz":-60,"elapsed":24054,"user":{"displayName":"Daan Koomen","userId":"05289433156715552258"}},"outputId":"63fd45bf-a8bc-4e31-9678-54a6c778cd0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import sys\n","import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","py_file_location = \"/drive location here\"\n","sys.path.append(os.path.abspath(py_file_location))\n"]},{"cell_type":"code","source":["#import os\n","import shutil\n","\n","import torch\n","import torch.utils.data\n","# import torch.utils.data.distributed\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","import argparse\n","import re\n","\n","from helpers import makedir\n","import model\n","import push\n","import prune\n","import train_and_test as tnt\n","import save\n","from log import create_logger\n","from preprocess import mean, std, preprocess_input_function\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('-gpuid', nargs=1, type=str, default='0') # python3 main.py -gpuid=0,1,2,3\n","args = parser.parse_args(args=[])\n","os.environ['CUDA_VISIBLE_DEVICES'] = args.gpuid[0]\n","\n","# book keeping namings and code\n","from settings import base_architecture, img_size, prototype_shape, num_classes, \\\n","                     prototype_activation_function, add_on_layers_type, experiment_run\n","\n","base_architecture_type = re.match('^[a-z]*', base_architecture).group(0)\n","\n","model_dir = py_file_location + '/' +'saved_models/' + base_architecture + '/' + experiment_run + '/'\n","\n","makedir(model_dir)\n","shutil.copy(src=os.path.join(py_file_location, 'main.ipynb'), dst=model_dir)\n","shutil.copy(src=os.path.join(py_file_location, 'settings.py'), dst=model_dir)\n","shutil.copy(src=os.path.join(py_file_location, base_architecture_type + '_features.py'), dst=model_dir)\n","shutil.copy(src=os.path.join(py_file_location, 'model.py'), dst=model_dir)\n","shutil.copy(src=os.path.join(py_file_location, 'train_and_test.py'), dst=model_dir)\n","\n","\n","log, logclose = create_logger(log_filename=os.path.join(model_dir, 'train.log'))\n","img_dir = os.path.join(model_dir, 'img')\n","makedir(img_dir)\n","weight_matrix_filename = 'outputL_weights'\n","prototype_img_filename_prefix = 'prototype-img'\n","prototype_self_act_filename_prefix = 'prototype-self-act'\n","proto_bound_boxes_filename_prefix = 'bb'\n","\n","# load the data\n","from settings import train_dir, test_dir, train_push_dir, \\\n","                     train_batch_size, test_batch_size, train_push_batch_size\n","\n","normalize = transforms.Normalize(mean=mean,\n","                                 std=std)\n","\n","# all datasets\n","# train set\n","train_dataset = datasets.ImageFolder(\n","    train_dir,\n","    transforms.Compose([\n","        transforms.Resize(size=(img_size, img_size)),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]))\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True,\n","    num_workers=4, pin_memory=False)\n","# push set\n","train_push_dataset = datasets.ImageFolder(\n","    train_push_dir,\n","    transforms.Compose([\n","        transforms.Resize(size=(img_size, img_size)),\n","        transforms.ToTensor(),\n","    ]))\n","train_push_loader = torch.utils.data.DataLoader(\n","    train_push_dataset, batch_size=train_push_batch_size, shuffle=False,\n","    num_workers=4, pin_memory=False)\n","# test set\n","test_dataset = datasets.ImageFolder(\n","    test_dir,\n","    transforms.Compose([\n","        transforms.Resize(size=(img_size, img_size)),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]))\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=test_batch_size, shuffle=False,\n","    num_workers=4, pin_memory=False)\n","\n","# we should look into distributed sampler more carefully at torch.utils.data.distributed.DistributedSampler(train_dataset)\n","log('training set size: {0}'.format(len(train_loader.dataset)))\n","log('push set size: {0}'.format(len(train_push_loader.dataset)))\n","log('test set size: {0}'.format(len(test_loader.dataset)))\n","log('batch size: {0}'.format(train_batch_size))\n","\n","# construct the model\n","ppnet = model.construct_PPNet(base_architecture=base_architecture,\n","                              pretrained=False, img_size=img_size,\n","                              prototype_shape=prototype_shape,\n","                              num_classes=num_classes,\n","                              prototype_activation_function=prototype_activation_function,\n","                              add_on_layers_type=add_on_layers_type)\n","#if prototype_activation_function == 'linear':\n","#    ppnet.set_last_layer_incorrect_connection(incorrect_strength=0)\n","ppnet = ppnet.cuda()\n","ppnet_multi = torch.nn.DataParallel(ppnet)\n","class_specific = True\n","\n","# def count_parameters(model):\n","#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# count_parameters(ppnet)\n","\n","# for parameter in ppnet.parameters():\n","#     print(parameter)\n","\n","# define optimizer\n","from settings import joint_optimizer_lrs, joint_lr_step_size\n","joint_optimizer_specs = \\\n","[{'params': ppnet.features.parameters(), 'lr': joint_optimizer_lrs['features'], 'weight_decay': 1e-3}, # bias are now also being regularized\n"," {'params': ppnet.add_on_layers.parameters(), 'lr': joint_optimizer_lrs['add_on_layers'], 'weight_decay': 1e-3},\n"," {'params': ppnet.prototype_vectors, 'lr': joint_optimizer_lrs['prototype_vectors']},\n","]\n","joint_optimizer = torch.optim.Adam(joint_optimizer_specs)\n","joint_lr_scheduler = torch.optim.lr_scheduler.StepLR(joint_optimizer, step_size=joint_lr_step_size, gamma=0.1)\n","\n","from settings import warm_optimizer_lrs\n","warm_optimizer_specs = \\\n","[{'params': ppnet.add_on_layers.parameters(), 'lr': warm_optimizer_lrs['add_on_layers'], 'weight_decay': 1e-3},\n"," {'params': ppnet.prototype_vectors, 'lr': warm_optimizer_lrs['prototype_vectors']},\n","]\n","warm_optimizer = torch.optim.Adam(warm_optimizer_specs)\n","\n","from settings import last_layer_optimizer_lr\n","last_layer_optimizer_specs = [{'params': ppnet.last_layer.parameters(), 'lr': last_layer_optimizer_lr}]\n","last_layer_optimizer = torch.optim.Adam(last_layer_optimizer_specs)\n","\n","# weighting of different training losses\n","from settings import coefs\n","\n","# number of training epochs, number of warm epochs, push start epoch, push epochs\n","from settings import num_train_epochs, num_warm_epochs, push_start, push_epochs\n","\n","# train the model\n","log('start training')\n","import copy\n","for epoch in range(num_train_epochs):\n","    log('epoch: \\t{0}'.format(epoch))\n","\n","    if epoch < num_warm_epochs:\n","        tnt.warm_only(model=ppnet_multi, log=log)\n","        _ = tnt.train(model=ppnet_multi, dataloader=train_loader, optimizer=warm_optimizer,\n","                      class_specific=class_specific, coefs=coefs, log=log)\n","    else:\n","        tnt.joint(model=ppnet_multi, log=log)\n","        joint_lr_scheduler.step()\n","        _ = tnt.train(model=ppnet_multi, dataloader=train_loader, optimizer=joint_optimizer,\n","                      class_specific=class_specific, coefs=coefs, log=log)\n","\n","    accu = tnt.test(model=ppnet_multi, dataloader=test_loader,\n","                    class_specific=class_specific, log=log)\n","    save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + 'nopush', accu=accu,\n","                                target_accu=0.8, log=log)\n","\n","    if epoch >= push_start and epoch in push_epochs:\n","        push.push_prototypes(\n","            train_push_loader, # pytorch dataloader (must be unnormalized in [0,1])\n","            prototype_network_parallel=ppnet_multi, # pytorch network with prototype_vectors\n","            class_specific=class_specific,\n","            preprocess_input_function=preprocess_input_function, # normalize if needed\n","            prototype_layer_stride=1,\n","            root_dir_for_saving_prototypes=img_dir, # if not None, prototypes will be saved here\n","            epoch_number=epoch, # if not provided, prototypes saved previously will be overwritten\n","            prototype_img_filename_prefix=prototype_img_filename_prefix,\n","            prototype_self_act_filename_prefix=prototype_self_act_filename_prefix,\n","            proto_bound_boxes_filename_prefix=proto_bound_boxes_filename_prefix,\n","            save_prototype_class_identity=True,\n","            log=log)\n","        accu = tnt.test(model=ppnet_multi, dataloader=test_loader,\n","                        class_specific=class_specific, log=log)\n","        save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + 'push', accu=accu,\n","                                    target_accu=0.8, log=log)\n","\n","        if prototype_activation_function != 'linear':\n","            tnt.last_only(model=ppnet_multi, log=log)\n","            for i in range(20):\n","                log('iteration: \\t{0}'.format(i))\n","                _ = tnt.train(model=ppnet_multi, dataloader=train_loader, optimizer=last_layer_optimizer,\n","                              class_specific=class_specific, coefs=coefs, log=log)\n","                accu = tnt.test(model=ppnet_multi, dataloader=test_loader,\n","                                class_specific=class_specific, log=log)\n","                save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + '_' + str(i) + 'push', accu=accu,\n","                                            target_accu=0.8, log=log)\n","   \n","logclose()\n"],"metadata":{"id":"Y_mqtaDKhHrx"},"execution_count":null,"outputs":[]}]}